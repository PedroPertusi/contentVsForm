{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6761db11",
   "metadata": {},
   "source": [
    "# SCORING NOTEBOOK \n",
    "- requires previous low_scorer and high_scorer runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Target & features setup\n",
    "TARGET_COL = \"holistic_essay_score\"\n",
    "TEXT_COL = \"text\"\n",
    "CATEGORICAL_COLS = ['gender', 'grade_level', 'race_ethnicity', 'economically_disadvantaged']\n",
    "\n",
    "SAVE_DIR = \"../data/results/\"\n",
    "SAVE_NAME = \"data_no_desc_scored_final.csv\"\n",
    "\n",
    "# Rewrites\n",
    "REWRITE = \"paraphrase\"  # \"paraphrase\" or \"random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5213def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# academic = pd.read_csv(\"../cleaned_data/rewrites/prompted/academic_full.csv\")\n",
    "# good_student = pd.read_csv(\"../cleaned_data/rewrites/prompted/good_student_full.csv\")\n",
    "# neutral = pd.read_csv(\"../cleaned_data/rewrites/prompted/neutral_full.csv\")\n",
    "# no_descriptions = pd.read_csv(\"../cleaned_data/rewrites/prompted/no_descriptions_full.csv\")\n",
    "# simple_english = pd.read_csv(\"../cleaned_data/rewrites/prompted/simple_english_full.csv\")\n",
    "# original = pd.read_csv(\"../cleaned_data/rewrites/prompted/original_full_fold.csv\")\n",
    "\n",
    "# academic_emb = np.load(\"../embeddings/scorer_input/embeddings_academic.npy\")\n",
    "# good_student_emb = np.load(\"../embeddings/scorer_input/embeddings_good_student.npy\")\n",
    "# neutral_emb = np.load(\"../embeddings/scorer_input/embeddings_neutral.npy\")\n",
    "# no_descriptions_emb = np.load(\"../embeddings/scorer_input/embeddings_no_descriptions.npy\")\n",
    "# simple_english_emb = np.load(\"../embeddings/scorer_input/embeddings_simple_english.npy\")\n",
    "# original_emb = np.load(\"../embeddings/scorer_input/embeddings_original.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv(\"../data/full/data_full_no_preproc.csv\")\n",
    "rew_0 = pd.read_csv(\"../data/rewrites/no_desc/no_desc_rewritten_0_cleaned.csv\")\n",
    "rew_1 = pd.read_csv(\"../data/rewrites/no_desc/no_desc_rewritten_1_cleaned.csv\")\n",
    "rew_2 = pd.read_csv(\"../data/rewrites/no_desc/no_desc_rewritten_2_cleaned.csv\")\n",
    "rew_3 = pd.read_csv(\"../data/rewrites/no_desc/no_desc_rewritten_3_cleaned.csv\")\n",
    "rew_4 = pd.read_csv(\"../data/rewrites/no_desc/no_desc_rewritten_4_cleaned.csv\")\n",
    "rew_5 = pd.read_csv(\"../data/rewrites/no_desc/no_desc_rewritten_5_cleaned.csv\")\n",
    "\n",
    "original_emb = np.load(\"../embeddings/embeddings_original_full.npy\")\n",
    "rew_0_emb = np.load(\"../embeddings/no_desc/embeddings_rewritten_0.npy\")\n",
    "rew_1_emb = np.load(\"../embeddings/no_desc/embeddings_rewritten_1.npy\")\n",
    "rew_2_emb = np.load(\"../embeddings/no_desc/embeddings_rewritten_2.npy\")\n",
    "rew_3_emb = np.load(\"../embeddings/no_desc/embeddings_rewritten_3.npy\")\n",
    "rew_4_emb = np.load(\"../embeddings/no_desc/embeddings_rewritten_4.npy\")\n",
    "rew_5_emb = np.load(\"../embeddings/no_desc/embeddings_rewritten_5.npy\")\n",
    "\n",
    "DATASET_REW = {\n",
    "    \"original\": original,\n",
    "    0: rew_0,\n",
    "    1: rew_1,\n",
    "    2: rew_2,\n",
    "    3: rew_3,\n",
    "    4: rew_4,\n",
    "    5: rew_5\n",
    "}\n",
    "\n",
    "DATASET_EMB = {\n",
    "    \"original\": original_emb,\n",
    "    0: rew_0_emb,\n",
    "    1: rew_1_emb,\n",
    "    2: rew_2_emb,\n",
    "    3: rew_3_emb,\n",
    "    4: rew_4_emb,\n",
    "    5: rew_5_emb\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aaa79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# 1) sanity check: all DFs must have same length as `original`\n",
    "n = original.shape[0]\n",
    "assert all(len(df_) == n for df_ in list(DATASET_REW.values())), \\\n",
    "    \"Lengths differ between original and rewrites.\"\n",
    "\n",
    "# 2) generate one UUID per paper\n",
    "paper_ids = [str(uuid.uuid4()) for _ in range(n)]\n",
    "\n",
    "# 3) assign to every DF + set cv_fold = 1\n",
    "for df_ in list(DATASET_REW.values()):\n",
    "    df_.loc[:, \"paper_id\"] = paper_ids\n",
    "\n",
    "for df_ in list(DATASET_REW.values()):\n",
    "    df_[\"cv_fold\"] = original['cv_fold']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e0a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xgb(path: Path) -> XGBRegressor:\n",
    "    m = XGBRegressor()\n",
    "    m.load_model(str(path))\n",
    "    return m\n",
    "\n",
    "# Map your logical group names to their folder names\n",
    "SUBFOLDERS = {\n",
    "    \"full\":   \"x_full\",\n",
    "    \"style\":  \"x_style\",\n",
    "    \"emb\":    \"x_emb\",\n",
    "    \"taassc\": \"x_taassc\",\n",
    "    \"taaco\":  \"x_taaco\",\n",
    "    \"taaled\": \"x_taaled\",\n",
    "}\n",
    "\n",
    "def build_models(root=\"../cleaned_data\", folds=5):\n",
    "    root = Path(root)\n",
    "    return {\n",
    "        group: {\n",
    "            side: {\n",
    "                i: load_xgb(root / f\"model_{side}\" / sub / f\"xgb_fold{i}.json\")\n",
    "                for i in range(1, folds + 1)\n",
    "            }\n",
    "            for side in (\"high\", \"low\")\n",
    "        }\n",
    "        for group, sub in SUBFOLDERS.items()\n",
    "    }\n",
    "\n",
    "models = build_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ebe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_k = {\n",
    "    \"original\": 0,\n",
    "    0: 1,\n",
    "    1: 2,\n",
    "    2: 3,\n",
    "    3: 4,\n",
    "    4: 5,\n",
    "    5: 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c72c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\"full\", \"style\", \"emb\", \"taaled\", \"taaco\", \"taassc\"]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for name, df_ in DATASET_REW.items():\n",
    "\n",
    "    # --- Build feature DF x (keep df_ unchanged)\n",
    "    if name != \"original\":\n",
    "        x = df_.drop(columns=[\"full_text\",\"text_tokens\",f\"content_preserved_{name}\",f\"rewritten_text_{name}\",\"text\"], errors=\"ignore\").copy()\n",
    "    else:\n",
    "        x = df_.drop(columns=[\"full_text\",\"text_tokens\",\"text\"], errors=\"ignore\").copy()\n",
    "\n",
    "    # --- Keep references for output\n",
    "    true_score = x[\"holistic_essay_score\"].copy()\n",
    "    paper_ids  = x[\"paper_id\"].copy()\n",
    "    low_ses    = x[\"economically_disadvantaged_1\"].copy()\n",
    "    race       = x[\"race_ethnicity_White\"].copy()\n",
    "    gender     = x[\"gender_M\"].copy()\n",
    "    prompt     = x[\"prompt_name\"].copy()\n",
    "    cv_fold    = x[\"cv_fold\"].astype(int).copy()\n",
    "\n",
    "    # --- Remove label/meta cols from features\n",
    "    x = x.drop(columns=[\"paper_id\",\"cv_fold\",\"holistic_essay_score\",\"prompt_name\"], errors=\"ignore\")\n",
    "\n",
    "    # --- Column lists (derived from *x*, not global)\n",
    "    ohe_cols     = [c for c in x.columns if c.startswith(\"gender\") or c.startswith(\"grade_level\") or c.startswith(\"race_\") or c.startswith(\"economically_disadvantaged\")]\n",
    "    taaled_cols  = [c for c in x.columns if c.startswith(\"taaled_\")]\n",
    "    taaco_cols   = [c for c in x.columns if c.startswith(\"taaco_\")]\n",
    "    taassc_cols  = [c for c in x.columns if c.startswith(\"taassc_\")]\n",
    "\n",
    "    # --- Build feature matrices for each scorer\n",
    "    X_emb = DATASET_EMB[name]  # embedding matrix aligned row-wise to df_\n",
    "    X_by_group = {\n",
    "        \"full\":    np.hstack([x.to_numpy(), X_emb]),\n",
    "        \"style\":   x.to_numpy(),\n",
    "        \"emb\":     np.hstack([x[ohe_cols].to_numpy(), X_emb]),\n",
    "        \"taaled\":  x[ohe_cols + taaled_cols].to_numpy(),\n",
    "        \"taaco\":   x[ohe_cols + taaco_cols].to_numpy(),\n",
    "        \"taassc\":  x[ohe_cols + taassc_cols].to_numpy(),\n",
    "    }\n",
    "\n",
    "    # --- Prepare output arrays for all groups/sides\n",
    "    preds = {g: {\"high\": np.empty(len(x), float), \"low\": np.empty(len(x), float)} for g in groups}\n",
    "\n",
    "    # --- Predict per fold for each group\n",
    "    for f in (1, 2, 3, 4, 5):\n",
    "        mask = (cv_fold == f)\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        for g in groups:\n",
    "            Xf = X_by_group[g][mask]\n",
    "            preds[g][\"high\"][mask] = models[g][\"high\"][f].predict(Xf)\n",
    "            preds[g][\"low\"][mask]  = models[g][\"low\"][f].predict(Xf)\n",
    "\n",
    "    # --- Assemble row block with 14 score columns\n",
    "    out = {\n",
    "        \"essay_id\": paper_ids.values,\n",
    "        \"k\": np.full(len(paper_ids), name_to_k[name], dtype=int),\n",
    "        \"true_score\": true_score.values,\n",
    "        \"low_SES\": low_ses.values,\n",
    "        \"race_white\": race.values,\n",
    "        \"gender_male\": gender.values,\n",
    "        \"prompt_name\": prompt.values,\n",
    "        \"cv_fold\": cv_fold.values,\n",
    "    }\n",
    "    for g in groups:\n",
    "        out[f\"score_high_{g}\"] = preds[g][\"high\"]\n",
    "        out[f\"score_low_{g}\"]  = preds[g][\"low\"]\n",
    "\n",
    "    rows.append(pd.DataFrame(out))\n",
    "\n",
    "results_df = pd.concat(rows, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc29a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"{SAVE_DIR}{SAVE_NAME}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646b6aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
