{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e25b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas() \n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Target & features setup\n",
    "TARGET_COL = \"holistic_essay_score\"\n",
    "TEXT_COL = \"text\"\n",
    "CATEGORICAL_COLS = ['gender', 'grade_level', 'race_ethnicity', 'economically_disadvantaged']\n",
    "\n",
    "DF_LOW = \"../data/full/data_full_low.csv\"\n",
    "EMB_LOW = \"../embeddings/embeddings_low.npy\"\n",
    "\n",
    "SAVE_DIR = \"../model/run_01/low\"\n",
    "SAVE_NAME = \"data_low_scored.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f13919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DF_LOW)\n",
    "X_emb_metrics = np.load(EMB_LOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f131687",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = df.copy().drop(columns=['text', 'holistic_essay_score', 'prompt_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e188737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols = [c for c in df_input.columns if c.startswith(\"gender\") or c.startswith(\"grade_level\") or c.startswith(\"race_\") or c.startswith(\"economically_disadvantaged\")]\n",
    "taaled_cols = [c for c in df_input.columns if c.startswith(\"taaled_\")]\n",
    "taaco_cols = [c for c in df_input.columns if c.startswith(\"taaco_\")]\n",
    "taassc_cols = [c for c in df_input.columns if c.startswith(\"taassc_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f772d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['holistic_essay_score']\n",
    "\n",
    "x1 = np.hstack([df_input, X_emb_metrics]) # full (OHE + Emb + All Style)\n",
    "x2 = np.hstack([df_input]) # Style (OHE + Style)\n",
    "x3 = np.hstack([df_input[ohe_cols], X_emb_metrics]) # Embedding (OHE + Emb)\n",
    "x4 = np.hstack([df_input[ohe_cols], df_input[taaled_cols]]) # TAALED (OHE + TAALED)\n",
    "x5 = np.hstack([df_input[ohe_cols], df_input[taaco_cols]]) # TAACO (OHE + TAACO)\n",
    "x6 = np.hstack([df_input[ohe_cols], df_input[taassc_cols]]) # TAASSC (OHE + TAACO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24fcd16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base style features (everything in df_input)\n",
    "style_cols = list(df_input.columns)\n",
    "\n",
    "# OHE subset used in emb + all others\n",
    "ohe_cols_list = list(df_input[ohe_cols].columns)\n",
    "\n",
    "taaled_feature_cols = ohe_cols_list + list(df_input[taaled_cols].columns)\n",
    "taaco_feature_cols  = ohe_cols_list + list(df_input[taaco_cols].columns)\n",
    "taassc_feature_cols = ohe_cols_list + list(df_input[taassc_cols].columns)\n",
    "\n",
    "feature_meta = {\n",
    "    \"style\": style_cols,\n",
    "    \"emb_ohe\": ohe_cols_list,\n",
    "    \"taaled\": taaled_feature_cols,\n",
    "    \"taaco\": taaco_feature_cols,\n",
    "    \"taassc\": taassc_feature_cols,\n",
    "    \"emb_dim\": int(X_emb_metrics.shape[1]),\n",
    "}\n",
    "\n",
    "import json, os\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "with open(os.path.join(SAVE_DIR, \"feature_meta.json\"), \"w\") as f:\n",
    "    json.dump(feature_meta, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42bf45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- your feature sets ---\n",
    "feature_sets = {\n",
    "    \"x_full\":  x1,\n",
    "    \"x_style\": x2,\n",
    "    \"x_emb\": x3,\n",
    "    \"x_taaled\": x4,\n",
    "    \"x_taaco\": x5,\n",
    "    \"x_taassc\": x6,\n",
    "}\n",
    "\n",
    "# Ensure same number of rows across sets\n",
    "n_rows = len(next(iter(feature_sets.values())))\n",
    "assert all(len(v) == n_rows for v in feature_sets.values()), \"All X sets must have same # rows\"\n",
    "\n",
    "# Target as numpy\n",
    "y_arr = y.to_numpy() if hasattr(y, \"to_numpy\") else np.asarray(y)\n",
    "\n",
    "# Shared CV (same splits for every feature set)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_ids = np.full(n_rows, -1, dtype=np.int16)  # will be filled during first run\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "def to_numpy(X):\n",
    "    return X if isinstance(X, np.ndarray) else X.to_numpy()\n",
    "\n",
    "# Run CV for each feature set\n",
    "for tag, X_any in feature_sets.items():\n",
    "    X = to_numpy(X_any).astype(np.float32, copy=False)\n",
    "\n",
    "    oof_pred = np.full(n_rows, np.nan, dtype=np.float32)\n",
    "\n",
    "    # Train 5 folds\n",
    "    for fold, (trn_idx, val_idx) in enumerate(tqdm(kf.split(X), total=5, desc=f\"5-Fold CV ({tag})\"), start=1):\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            tree_method=\"hist\"\n",
    "        )\n",
    "        model.fit(X[trn_idx], y_arr[trn_idx])\n",
    "        m_dir = os.path.join(SAVE_DIR, tag)  # no leading slash\n",
    "        os.makedirs(m_dir, exist_ok=True)\n",
    "        model.save_model(os.path.join(m_dir, f\"xgb_fold{fold}.json\"))\n",
    "\n",
    "        # store fold id once, using the first feature set\n",
    "        if tag == list(feature_sets.keys())[0]:\n",
    "            fold_ids[val_idx] = fold\n",
    "\n",
    "        # OOF predictions for this feature set\n",
    "        oof_pred[val_idx] = model.predict(X[val_idx]).astype(np.float32)\n",
    "\n",
    "    # attach OOF column for this set\n",
    "    df[f\"xgb_oof_pred_{tag}\"] = oof_pred\n",
    "\n",
    "    # quick OOF RMSE for this set\n",
    "    rmse = mean_squared_error(y_arr, oof_pred)\n",
    "    print(f\"[{tag}] OOF RMSE: {rmse:.5f}\")\n",
    "\n",
    "# attach cv fold (1..5) once\n",
    "df[\"cv_fold\"] = fold_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7f045",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in [\"x_full\", \"x_style\", \"x_emb\", \"x_taaled\", \"x_taaco\", \"x_taassc\"]:\n",
    "    df[f\"xgb_oof_pred_{tag}_int\"] = (\n",
    "        np.rint(df[f\"xgb_oof_pred_{tag}\"])  # round to nearest int\n",
    "        .clip(1, 6)                         # keep within 1–6\n",
    "        .astype(np.int16)                   # store as int16\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da9a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df[\"holistic_essay_score\"].to_numpy()\n",
    "\n",
    "tag_labels = {\n",
    "    \"x_full\":  \"x_full (OHE + EMB + Style)\",\n",
    "    \"x_style\": \"x_style (OHE + Style)\",\n",
    "    \"x_emb\": \"x_emb (OHE + EMB)\", \n",
    "    \"x_taaled\": \"x_taaled (OHE + TAALED)\",\n",
    "    \"x_taaco\": \"x_taaco (OHE + TAACO)\",\n",
    "    \"x_taassc\": \"x_taassc (OHE + TAASSC)\",\n",
    "}\n",
    "\n",
    "for tag, label in tag_labels.items():\n",
    "    y_pred = df[f\"xgb_oof_pred_{tag}\"].to_numpy()\n",
    "\n",
    "    rmse = mean_squared_error(y_true, y_pred)  # RMSE\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"{label}: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da1c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df[\"holistic_essay_score\"]\n",
    "\n",
    "for tag, label in tag_labels.items():\n",
    "    y_pred = df[f\"xgb_oof_pred_{tag}_int\"]\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1  = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "    print(f\"{label}: Accuracy={acc:.4f}, F1-macro={f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c09f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = df[f\"xgb_oof_pred_x_full_int\"]\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[1,2,3,4,5,6])\n",
    "\n",
    "# normalize row-wise (%)\n",
    "cm_percent = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(8,6))\n",
    "im = plt.imshow(cm_percent, interpolation=\"nearest\", cmap=\"YlGnBu\")\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "\n",
    "# annotate with %\n",
    "for i in range(cm_percent.shape[0]):\n",
    "    for j in range(cm_percent.shape[1]):\n",
    "        plt.text(\n",
    "            j, i, f\"{cm_percent[i, j]:.1f}%\",\n",
    "            ha=\"center\", va=\"center\",\n",
    "            color=\"black\" if cm_percent[i, j] < 50 else \"white\"\n",
    "        )\n",
    "\n",
    "plt.xticks(ticks=np.arange(6), labels=[1,2,3,4,5,6])\n",
    "plt.yticks(ticks=np.arange(6), labels=[1,2,3,4,5,6])\n",
    "plt.xlabel(\"Predicted essay score\")\n",
    "plt.ylabel(\"True essay score\")\n",
    "plt.savefig(f\"../tables/sat_2/confusion_matrix_low.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b19e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag, label in tag_labels.items():\n",
    "    y_pred = df[f\"xgb_oof_pred_{tag}_int\"]\n",
    "\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,2,3,4,5,6])\n",
    "\n",
    "    # normalize row-wise (%)\n",
    "    cm_percent = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(8,6))\n",
    "    im = plt.imshow(cm_percent, interpolation=\"nearest\", cmap=\"YlGnBu\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "\n",
    "    # annotate with %\n",
    "    for i in range(cm_percent.shape[0]):\n",
    "        for j in range(cm_percent.shape[1]):\n",
    "            plt.text(\n",
    "                j, i, f\"{cm_percent[i, j]:.1f}%\",\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"black\" if cm_percent[i, j] < 50 else \"white\"\n",
    "            )\n",
    "\n",
    "    plt.xticks(ticks=np.arange(6), labels=[1,2,3,4,5,6])\n",
    "    plt.yticks(ticks=np.arange(6), labels=[1,2,3,4,5,6])\n",
    "    plt.xlabel(\"Predicted essay score\")\n",
    "    plt.ylabel(\"True essay score\")\n",
    "    plt.title(f\"Confusion Matrix - Low SES Ranker — {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe31aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{SAVE_DIR}{SAVE_NAME}\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
