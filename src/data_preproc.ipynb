{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714410ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Embedding\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "import torch\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy.util as _su\n",
    "import tempfile\n",
    "\n",
    "# Progress bars\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()  # apply/progress_apply ready\n",
    "\n",
    "# Custom preprocessing & TAASSC\n",
    "from utils.preproc import Preprocessor\n",
    "import TAASSC_215_dev as tdev\n",
    "from TAASSC_215_dev import LGR_Analysis, index_list\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Target & features setup\n",
    "TARGET_COL = \"holistic_essay_score\"\n",
    "TEXT_COL = \"text\"\n",
    "CATEGORICAL_COLS = ['gender', 'grade_level', 'race_ethnicity', 'economically_disadvantaged']\n",
    "\n",
    "SAVE_DIR = \"../data/rewrites/\"  # Directory to save processed data\n",
    "\n",
    "orig_cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d6b06f",
   "metadata": {},
   "source": [
    "---- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ceb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "academic = pd.read_csv(\"../data/input/academic_cleaned.csv\")\n",
    "good_student = pd.read_csv(\"../data/input/good_student_cleaned.csv\")\n",
    "neutral = pd.read_csv(\"../data/input/neutral_cleaned.csv\")\n",
    "no_descriptions = pd.read_csv(\"../data/input/no_descriptions_cleaned.csv\")\n",
    "simple_english = pd.read_csv(\"../data/input/simple_english_cleaned.csv\")\n",
    "original = pd.read_csv(\"../data/input/original_cleaned_prompt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "    'academic': academic,\n",
    "    'good_student': good_student,\n",
    "    'neutral': neutral,\n",
    "    'no_descriptions': no_descriptions,\n",
    "    'simple_english': simple_english,\n",
    "    'original': original\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, x in dfs.items():\n",
    "    dfs[name] = pd.get_dummies(x, columns=CATEGORICAL_COLS, drop_first=False, dummy_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a665ffa",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc128aa",
   "metadata": {},
   "source": [
    "### TAALED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c2c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"TAALED_1_4_1_Py3\") \n",
    "import TAALED_1_4_1 as TAALED\n",
    "\n",
    "class _Root:\n",
    "    def update_idletasks(self): pass\n",
    "TAALED.root = _Root()\n",
    "TAALED.system = \"L\"  \n",
    "\n",
    "# 3) SpaCy compatibility shim\n",
    "if not hasattr(_su, \"set_data_path\"):\n",
    "    _su.set_data_path = lambda *a, **k: None\n",
    "\n",
    "# 4) Configure which indices to run\n",
    "var_dict = {\n",
    "    \"aw\": 1, \"cw\": 1, \"fw\": 1,\n",
    "    \"simple_ttr\": 1, \"root_ttr\": 1, \"log_ttr\": 1, \"maas_ttr\": 1,\n",
    "    \"mattr\": 1, \"msttr\": 1, \"hdd\": 1,\n",
    "    \"mltd\": 1, \"mltd_ma\": 1, \"mtld_wrap\": 1,\n",
    "    \"indout\": 0,\n",
    "}\n",
    "\n",
    "def _detect_filename_col(res: pd.DataFrame) -> str:\n",
    "    candidates = {\"filename\",\"file\",\"file_name\",\"textname\",\"doc\",\"document\",\"name\"}\n",
    "    for c in res.columns:\n",
    "        if c.lower() in candidates:\n",
    "            return c\n",
    "    return res.columns[0]\n",
    "\n",
    "def _add_prefix_once(df: pd.DataFrame, prefix: str, exclude: set) -> pd.DataFrame:\n",
    "    \"\"\"Prefix columns unless they already start with the prefix; leave 'exclude' alone.\"\"\"\n",
    "    rename_map = {}\n",
    "    for c in df.columns:\n",
    "        if c in exclude:\n",
    "            continue\n",
    "        if not c.startswith(prefix):\n",
    "            rename_map[c] = f\"{prefix}{c}\"\n",
    "    return df.rename(columns=rename_map)\n",
    "\n",
    "def _run_taaled_on_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Run TAALED on a single df and merge results (prefixed with 'taaled_').\"\"\"\n",
    "    with tempfile.TemporaryDirectory() as tmp_in:\n",
    "        # write each text as {index}.txt\n",
    "        for i, txt in df[\"text\"].items():\n",
    "            with open(os.path.join(tmp_in, f\"{i}.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(txt if isinstance(txt, str) else \"\")\n",
    "\n",
    "        out_csv = os.path.join(tmp_in, \"taaled_out.csv\")\n",
    "        TAALED.main(tmp_in, out_csv, var_dict)\n",
    "\n",
    "        # load results\n",
    "        res = pd.read_csv(out_csv)\n",
    "\n",
    "    # normalize filename -> index\n",
    "    fn_col = _detect_filename_col(res)\n",
    "    res[\"__idx__\"] = res[fn_col].astype(str).str.replace(\".txt\", \"\", regex=False)\n",
    "\n",
    "    # ensure prefix 'taaled_' on all metric columns\n",
    "    exclude_cols = {fn_col, \"__idx__\"}\n",
    "    res = _add_prefix_once(res, prefix=\"taaled_\", exclude=exclude_cols).drop(columns=[fn_col])\n",
    "\n",
    "    # merge back\n",
    "    df[\"__idx__\"] = df.index.astype(str)\n",
    "    df = df.merge(res, how=\"left\", on=\"__idx__\").drop(columns=\"__idx__\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae2e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- UPDATE THE ORIGINAL `dfs` IN PLACE ----------\n",
    "print(\"Running TAALED on multiple DataFrames (updating `dfs` in place):\")\n",
    "for name, d in dfs.items():\n",
    "    print(f\"  • {name}: {len(d)} texts\")\n",
    "    dfs[name] = _run_taaled_on_df(d)\n",
    "\n",
    "os.chdir(orig_cwd)\n",
    "\n",
    "print(\"All DataFrames in `dfs` now include TAALED metrics with the 'taaled_' prefix (no duplicates).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50852d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, x in dfs.items():\n",
    "    x.to_csv(f\"{SAVE_DIR}{name}_taaled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbffeb26",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7426b9",
   "metadata": {},
   "source": [
    "### TAACO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f40a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"TAACO\")\n",
    "from TAACOnoGUI import runTAACO\n",
    "\n",
    "# 3️TAACO options (customize as needed)\n",
    "opts = {\n",
    "    \"sourceKeyOverlap\": False, \"sourceLSA\": False, \"sourceLDA\": False, \"sourceWord2vec\": False,\n",
    "    \"wordsAll\": True, \"wordsContent\": True, \"wordsFunction\": True,\n",
    "    \"wordsNoun\": True, \"wordsPronoun\": True, \"wordsArgument\": True,\n",
    "    \"wordsVerb\": True, \"wordsAdjective\": True, \"wordsAdverb\": True,\n",
    "    \"overlapSentence\": True, \"overlapParagraph\": True,\n",
    "    \"overlapAdjacent\": True, \"overlapAdjacent2\": True,\n",
    "    \"otherTTR\": True, \"otherConnectives\": True, \"otherGivenness\": True,\n",
    "    \"overlapLSA\": True, \"overlapLDA\": True, \"overlapWord2vec\": True,\n",
    "    \"overlapSynonym\": True, \"overlapNgrams\": True,\n",
    "    \"outputTagged\": False, \"outputDiagnostic\": False,\n",
    "}\n",
    "\n",
    "# Helper: detect TAACO filename column\n",
    "def _detect_filename_column(df_out):\n",
    "    for c in df_out.columns:\n",
    "        if c.lower() in {\"filename\",\"file\",\"file_name\",\"textname\",\"doc\",\"document\",\"name\"}:\n",
    "            return c\n",
    "    for c in df_out.columns:\n",
    "        if df_out[c].astype(str).str.endswith(\".txt\").any():\n",
    "            return c\n",
    "    return df_out.columns[0]\n",
    "\n",
    "def _add_prefix_once(df: pd.DataFrame, prefix: str, exclude: set) -> pd.DataFrame:\n",
    "    \"\"\"Prefix columns unless already prefixed.\"\"\"\n",
    "    rename_map = {}\n",
    "    for c in df.columns:\n",
    "        if c in exclude:\n",
    "            continue\n",
    "        if not c.startswith(prefix):\n",
    "            rename_map[c] = f\"{prefix}{c}\"\n",
    "    return df.rename(columns=rename_map)\n",
    "\n",
    "# Core function: run TAACO on one df and merge results\n",
    "def _run_taaco_on_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    with tempfile.TemporaryDirectory() as tmp_in:\n",
    "        # write each essay/text to temp folder\n",
    "        for i, txt in df[\"text\"].items():\n",
    "            with open(os.path.join(tmp_in, f\"{i}.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(txt if isinstance(txt, str) else \"\")\n",
    "\n",
    "        out_csv = os.path.join(tmp_in, \"taaco_out.csv\")\n",
    "        runTAACO(tmp_in, out_csv, opts)\n",
    "\n",
    "        # read TAACO results\n",
    "        res = pd.read_csv(out_csv)\n",
    "        fn_col = _detect_filename_column(res)\n",
    "        res[\"__idx__\"] = res[fn_col].astype(str).str.replace(\".txt\", \"\", regex=False)\n",
    "\n",
    "        # ensure prefix 'taaco_' on all metric columns\n",
    "        exclude_cols = {fn_col, \"__idx__\"}\n",
    "        res = _add_prefix_once(res, prefix=\"taaco_\", exclude=exclude_cols).drop(columns=[fn_col])\n",
    "\n",
    "        # merge results back\n",
    "        df[\"__idx__\"] = df.index.astype(str)\n",
    "        df = df.merge(res, how=\"left\", on=\"__idx__\").drop(columns=\"__idx__\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775bfcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Running TAACO on multiple DataFrames (updating `dfs` in place):\")\n",
    "for name, d in dfs.items():\n",
    "    print(f\"  • {name}: {len(d)} texts\")\n",
    "    dfs[name] = _run_taaco_on_df(d)\n",
    "\n",
    "os.chdir(orig_cwd)\n",
    "\n",
    "print(\"All DataFrames in `dfs` now include TAACO metrics with the 'taaco_' prefix (no duplicates).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62036e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, x in dfs.items():\n",
    "    x.to_csv(f\"{SAVE_DIR}{name}_taaled_taaco.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a78762",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7c754d",
   "metadata": {},
   "source": [
    "### TAASSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e571e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"taassc_\"        \n",
    "\n",
    "print(\"Running TAASSC on multiple DataFrames (updating `dfs` in place):\")\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    if TEXT_COL not in df.columns:\n",
    "        raise KeyError(f\"{name}: expected a '{TEXT_COL}' column. Got: {list(df.columns)[:12]}...\")\n",
    "\n",
    "    print(f\"\\nComputing TAASSC metrics for: {name} (n={len(df)})\")\n",
    "\n",
    "    # If re-running, drop any existing TAASSC-prefixed columns\n",
    "    taassc_cols_existing = [c for c in df.columns if c.startswith(PREFIX)]\n",
    "    if taassc_cols_existing:\n",
    "        df = df.drop(columns=taassc_cols_existing)\n",
    "\n",
    "    records = []\n",
    "    for txt in tqdm(df[TEXT_COL].fillna(\"\"), desc=f\"TAASSC → {name}\", total=len(df)):\n",
    "        try:\n",
    "            res = LGR_Analysis(txt)  # returns a dict for metrics in index_list\n",
    "            row = {metr: res.get(metr, np.nan) for metr in index_list}\n",
    "        except Exception as e:\n",
    "            print(f\"[{name}] Error processing text: {str(txt)[:100]}... -> {e}\")\n",
    "            row = {metr: np.nan for metr in index_list}\n",
    "        records.append(row)\n",
    "\n",
    "    # Build metrics DataFrame with prefixed column names\n",
    "    metrics_df = pd.DataFrame.from_records(records, index=df.index)\n",
    "    metrics_df.columns = [f\"{PREFIX}{metr}\" for metr in index_list]\n",
    "\n",
    "    # Merge back and update dict in place\n",
    "    df_out = pd.concat([df, metrics_df], axis=1)\n",
    "    dfs[name] = df_out\n",
    "\n",
    "    print(f\" {name}: TAASSC metrics added ({len(index_list)} features). New shape: {df_out.shape}\")\n",
    "\n",
    "print(\"\\n All DataFrames in `dfs` updated with TAASSC metrics (prefix='taassc_', TEXT_COL='text').\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf045e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, x in dfs.items():\n",
    "    x.to_csv(f\"{SAVE_DIR}{name}_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a60a97",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1409dd",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e487235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps') if (torch.backends.mps.is_available()) else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').eval().to(device)\n",
    "\n",
    "def get_embeddings(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Run one text through BERT, return the [CLS] embedding as a numpy vector.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text,\n",
    "                       return_tensors='pt',\n",
    "                       padding=True,\n",
    "                       truncation=True,\n",
    "                       max_length=512)\n",
    "    # move to device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # [batch=1, seq, dim] → pick CLS token embedding\n",
    "    cls_emb = outputs.last_hidden_state[0, 0, :]\n",
    "    return cls_emb.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9e6e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../embeddings/\", exist_ok=True)\n",
    "\n",
    "for i, df_i in dfs.items():\n",
    "    emb_list = []\n",
    "\n",
    "    for txt in tqdm(df_i[\"text\"], desc=f\"Rewritten {i}\"):\n",
    "        emb = get_embeddings(txt)\n",
    "        emb_list.append(emb)\n",
    "\n",
    "    X_emb = np.vstack(emb_list)\n",
    "    np.save(f\"../embeddings/embeddings_{i}.npy\", X_emb)\n",
    "\n",
    "print(\"All rewrite embeddings computed and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
